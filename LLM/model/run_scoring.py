from pathlib import Path
import re
import argparse
import os
import sys
sys.path.append(os.path.dirname(__file__))
from analyze_images_with_gpt import analyze_image_with_gpt, PROMPT, IMAGE_DIR
import numpy as np
from collections import defaultdict
import openai

from difflib import SequenceMatcher
import json

def is_similar(a, b, threshold=0.8):
    return SequenceMatcher(None, a, b).ratio() > threshold

# ê²½ë¡œ ìƒìˆ˜ ì •ì˜
DOCS_DIR = os.path.join(os.path.dirname(__file__), '../docs')
TEST_IMG_DIR = os.path.join(os.path.dirname(__file__), '../test_images')
MODEL_DIR = os.path.dirname(__file__)
IMAGE_DIR = os.path.join(os.path.dirname(__file__), '../detection_results/images')

def load_rag_docs():
    base_path = Path("./")
    files = {
        "house": base_path / "rag_doc_house.md",
        "tree": base_path / "rag_doc_tree.md",
        "person": base_path / "rag_doc_person.md"
    }
    rag_data = {}
    for k, path in files.items():
        rag_data[k] = path.read_text(encoding="utf-8")
    return rag_data

def parse_rag_markdown(md_text):
    pattern = r"- ìš”ì†Œ:\s*(.*?)\n- ì¡°ê±´:\s*(.*?)\n- ê°ì • í‚¤ì›Œë“œ:\s*(.*?)\n"
    return {(m[0], m[1]): m[2] for m in re.findall(pattern, md_text)}

def load_emotion_keywords():
    data = Path(os.path.join(DOCS_DIR, "emotion_keywords.md")).read_text(encoding="utf-8")
    category_map = {}
    current_category = None
    for line in data.splitlines():
        if line.startswith("### "):
            current_category = line.replace("### ", "").strip()
        elif line.strip() and current_category:
            keywords = [k.strip() for k in line.split(",") if k.strip()]
            for k in keywords:
                category_map[k] = current_category
    return category_map

def score_persona(elements, rag_maps, keyword_map):
    scores = {"ì¶”ì§„í˜•": 0, "ê´€ê³„í˜•": 0, "ì•ˆì •í˜•": 0, "ì¾Œë½í˜•": 0, "ë‚´ë©´í˜•": 0}
    for elem in elements:
        key = (elem["element"], elem["condition"])
        doc = rag_maps[elem["category"]]
        keyword = doc.get(key)
        if keyword:
            mapped_type = keyword_map.get(keyword)
            if mapped_type:
                scores[mapped_type] += 1
    return scores

# ìš”ì†Œ/ì¡°ê±´/ì¹´í…Œê³ ë¦¬ ì¶”ì¶œì„ ìœ„í•œ íŒŒì„œ í•¨ìˆ˜ (ì˜ˆì‹œ)
def parse_elements_from_analysis(analysis_text):
    # "1. ì‹¬ë¦¬ ë¶„ì„ ìš”ì†Œ ì‹ë³„" ~ "2. ìš”ì†Œë³„ ì‹¬ì¸µ ë¶„ì„" ì‚¬ì´ì˜ ëª©ë¡ë§Œ ì¶”ì¶œ
    import re
    elements = []
    # 1ë²ˆ í•­ëª© ì¶”ì¶œ
    m = re.search(r"1\. \*\*ì‹¬ë¦¬ ë¶„ì„ ìš”ì†Œ ì‹ë³„\*\*:(.*?)2\. ", analysis_text, re.DOTALL)
    if not m:
        return elements
    block = m.group(1)
    # ê° ì¤„ì—ì„œ ìš”ì†Œ/ì¡°ê±´/ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ (ì˜ˆ: '- ì§‘: ì§€ë¶•ì— ìˆëŠ” ì°½ë¬¸, ê²©ìë¬´ëŠ¬')
    for line in block.splitlines():
        line = line.strip('-â€¢* ').strip()
        if not line or ':' not in line:
            continue
        # ì˜ˆì‹œ: 'ì§‘: ì§€ë¶•ì— ìˆëŠ” ì°½ë¬¸, ê²©ìë¬´ëŠ¬'
        category, rest = line.split(':', 1)
        element, *condition = rest.split(',', 1)
        elements.append({
            'category': category.strip(),
            'element': element.strip(),
            'condition': condition[0].strip() if condition else ''
        })
    return elements

# ê°ì • í‚¤ì›Œë“œì™€ ìœ í˜• ë§¤í•‘ íŒŒì‹± í•¨ìˆ˜
def parse_emotion_keywords_md(md_path="emotion_keywords.md"):
    type_map = {}
    current_type = None
    with open(os.path.join(DOCS_DIR, md_path), encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if line.startswith("## "):
                continue
            if line.startswith("### "):
                current_type = line.replace("### ", "").replace("íŠ¹ì§• ìš”ì•½", "").strip()
            elif line.startswith("- ") and current_type and not line.startswith("---"):
                kw = line[2:].strip()
                if kw:
                    type_map[kw] = current_type
    return type_map

# ê°ì • í‚¤ì›Œë“œ ì„ë² ë”© ìƒì„± í•¨ìˆ˜
EMBED_MODEL = "text-embedding-3-small"
def get_embedding(text):
    return openai.embeddings.create(input=text, model=EMBED_MODEL).data[0].embedding

def cosine_similarity(a, b):
    a, b = np.array(a), np.array(b)
    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))

# analyze_images_with_gpt ê²°ê³¼ì—ì„œ ê°ì • í‚¤ì›Œë“œë§Œ ì¶”ì¶œ
# (1, 2, 3ë²ˆ í•­ëª© ì „ì²´ì—ì„œ ì‰¼í‘œ/ìŠ¬ë˜ì‹œ/ìŠ¤í˜ì´ìŠ¤ ë“±ìœ¼ë¡œ ë¶„ë¦¬)
def extract_result_keywords(analysis_text):
    import re
    # 1, 2, 3ë²ˆ í•­ëª© ì „ì²´ ì¶”ì¶œ
    matches = re.findall(r"\d+\. ?\*\*.*?\*\*:?(.+?)(?=\n\d+\.|$)", analysis_text, re.DOTALL)
    keywords = []
    for block in matches:
        # í•œ ì¤„ì”© ë¶„ë¦¬ í›„, ì‰¼í‘œ/ìŠ¬ë˜ì‹œ/ìŠ¤í˜ì´ìŠ¤ ë“±ìœ¼ë¡œ ë¶„ë¦¬
        for line in block.splitlines():
            for k in re.split(r"[\s,\/]+", line.strip()):
                if k:
                    keywords.append(k)
    return list(set(keywords))  # ì¤‘ë³µ ì œê±°

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="ë¶„ì„í•  detection_result_*.jpg íŒŒì¼ëª…ì„ ì§€ì •í•˜ì„¸ìš”.")
    parser.add_argument('--image', type=str, required=True, help='ë¶„ì„í•  ì›ë³¸ ì´ë¯¸ì§€ íŒŒì¼ëª… (ì˜ˆ: test4.jpg ë˜ëŠ” test4)')
    parser.add_argument('--embedding', action='store_true', help='ì„ë² ë”© ê¸°ë°˜ ê°ì •ìœ í˜• ë¶„ì„ ì‹¤í–‰')
    args = parser.parse_args()

    # detection_result_*.jpg ê²½ë¡œ ìƒì„±
    image_base = os.path.splitext(args.image)[0]
    target_filename = f"detection_result_{image_base}.jpg"
    image_path = os.path.join(IMAGE_DIR, target_filename)
    if not os.path.exists(image_path):
        print(f"{IMAGE_DIR} í´ë”ì— {target_filename} íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        exit(1)

    # GPT ë¶„ì„ ê²°ê³¼ ì–»ê¸°
    try:
        analysis_text = analyze_image_with_gpt(image_path, PROMPT)
    except Exception as e:
        print(f"ë¶„ì„ ì‹¤íŒ¨: {e}")
        exit(1)

    if args.embedding:
        type_map = parse_emotion_keywords_md(os.path.join(DOCS_DIR, "emotion_keywords.md"))
        emotion_keywords = list(type_map.keys())
        keyword_embeddings = {kw: get_embedding(kw) for kw in emotion_keywords}
        result_keywords = extract_result_keywords(analysis_text)
        N = 5
        final_scores = defaultdict(int)
        for rk in result_keywords:
            rk_emb = get_embedding(rk)
            sims = [(kw, cosine_similarity(rk_emb, emb)) for kw, emb in keyword_embeddings.items()]
            sims.sort(key=lambda x: x[1], reverse=True)
            top_n = sims[:N]
            for kw, _ in top_n:
                t = type_map[kw]
                final_scores[t] += 1
        if final_scores:
            print("ì„ë² ë”© ê¸°ë°˜ ê°ì •ìœ í˜• ì ìˆ˜:", dict(final_scores))
            print("ì„ë² ë”© ê¸°ë°˜ ìµœì¢… ê°ì •ìœ í˜•:", max(final_scores, key=final_scores.get))
        else:
            print("ì„ë² ë”© ê¸°ë°˜ ê°ì •ìœ í˜• ì ìˆ˜ ì—†ìŒ")
        exit(0)

    extracted_elements = parse_elements_from_analysis(analysis_text)
    if not extracted_elements:
        print("ë¶„ì„ ìš”ì†Œë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        exit(1)

    # ê¸°ì¡´ ì ìˆ˜ ê³„ì‚° ë¡œì§
    rag_raw = load_rag_docs()
    rag_maps = {k: parse_rag_markdown(v) for k, v in rag_raw.items()}
    keyword_map = load_emotion_keywords()

    result = score_persona(extracted_elements, rag_maps, keyword_map)
    print("ìµœì¢… ì ìˆ˜:", result)
    print("ì˜ˆì¸¡ ìœ í˜•:", max(result, key=result.get))


# Inserted matching block

    for (elem, cond), emotions in parsed.items():
        matched = False
        for (rag_elem, rag_cond), rag_info in rag_data.items():
            if is_similar(elem, rag_elem) and is_similar(cond, rag_cond):
                matched = True
                print(f"ğŸŸ¢ ë§¤ì¹­ëœ í•­ëª©: ìš”ì†Œ='{elem}', ì¡°ê±´='{cond}' â†’ ê°ì • í‚¤ì›Œë“œ: {rag_info['ê°ì • í‚¤ì›Œë“œ']}")
                keywords = [k.strip() for k in rag_info["ê°ì • í‚¤ì›Œë“œ"].split(",")]
                for kw in keywords:
                    if kw in emotion_to_persona:
                        scores[emotion_to_persona[kw]] += 1
                matched_results.append((elem, cond, rag_info["í•´ì„ ì„¤ëª…"]))
                break
        if not matched:
            print(f"âš ï¸ ë§¤ì¹­ ì‹¤íŒ¨: ìš”ì†Œ='{elem}', ì¡°ê±´='{cond}'")

